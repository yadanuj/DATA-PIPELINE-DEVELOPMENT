{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhJ/uIOxBh5Z0XcU2aD+Jx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"gfYDRFnqGEkt","executionInfo":{"status":"ok","timestamp":1752499696270,"user_tz":-330,"elapsed":327,"user":{"displayName":"Akshat","userId":"14008984325345801619"}},"outputId":"c99501a9-d8e0-4f33-b255-967813faaa6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üì¶ Extracting data...\n","\n","üîß Transforming data...\n","\n","üíæ Saving data to disk...\n","Data saved as: processed_data.csv\n","\n","‚¨áÔ∏è Downloading the processed CSV file...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_5a799d85-289b-49d7-87c7-d75615ef043b\", \"processed_data.csv\", 3414105)"]},"metadata":{}}],"source":["# California Housing ETL Pipeline - Google Colab Version\n","\n","# ‚úÖ STEP 1: Import libraries\n","import pandas as pd\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import files\n","\n","# ‚úÖ STEP 2: Define ETL Functions\n","def extract_data():\n","    print(\"\\nüì¶ Extracting data...\")\n","    dataset = fetch_california_housing(as_frame=True)\n","    df = dataset.frame\n","    return df\n","\n","def transform_data(df):\n","    print(\"\\nüîß Transforming data...\")\n","    # Check for missing values\n","    if df.isnull().sum().sum() > 0:\n","        df = df.dropna()\n","\n","    # Feature scaling (except target column)\n","    features = df.drop(\"MedHouseVal\", axis=1)\n","    scaler = StandardScaler()\n","    scaled_features = scaler.fit_transform(features)\n","\n","    # Combine scaled features with target\n","    scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n","    scaled_df[\"MedHouseVal\"] = df[\"MedHouseVal\"].values\n","    return scaled_df\n","\n","def load_data(df, output_path=\"processed_data.csv\"):\n","    print(\"\\nüíæ Saving data to disk...\")\n","    df.to_csv(output_path, index=False)\n","    print(f\"Data saved as: {output_path}\")\n","    return output_path\n","\n","# ‚úÖ STEP 3: Run the ETL Pipeline\n","def run_etl_pipeline():\n","    df_raw = extract_data()\n","    df_transformed = transform_data(df_raw)\n","    csv_path = load_data(df_transformed)\n","    return csv_path\n","\n","# ‚úÖ STEP 4: Execute and Download\n","csv_path = run_etl_pipeline()\n","\n","# ‚úÖ STEP 5: Download the file\n","print(\"\\n‚¨áÔ∏è Downloading the processed CSV file...\")\n","files.download(csv_path)\n"]}]}
